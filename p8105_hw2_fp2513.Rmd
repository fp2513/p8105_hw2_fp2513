---
title: "p8105_hw2_fp2513"
output: github_document
---

```{r setup, echo = FALSE, message = FALSE}
library(tidyverse)
library(readxl)
library(haven)
```

## Problem 1

**Read and clean the data; retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. Convert the entry variable from character (YES vs NO) to a logical variable (the ifelse or case_match function may be useful).**

```{r}
NYC_Transit_df = 
  read_csv(file = "NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
           na = c("NA", ",", ".")) %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(
    entry = 
      case_match(
        entry, 
        "NO" ~ FALSE, 
        "YES" ~ TRUE),
    entry = as.logical(entry))

```

**Write a short paragraph about this dataset â€“ explain briefly what variables the dataset contains, describe your data cleaning steps so far, and give the dimension (rows x columns) of the resulting dataset. Are these data tidy?**

After importing and intial cleaning of the data, the NYC_Transit_df contains 1868 observations (each having its own row; 1868 rows) and 19 variables (19 columns). The data cleaning steps so far include:

1.    First defining the cells with NA, . and empty cells are used to indicate a missing value. 

2.    Then using `janitor::clean_names()` to clean up the variable column names to a consistent lower snake case. 

3.    Next, `select()` specified the columns that I wanted to keep, including the range from line to entry, and additional vending and ada columns

4.    Lastly, `mutate()` converted the inputs in the entry column from characters to logical variables. Specifically, using `case_match` to chnage every "YES" and "NO" input respectively became "TRUE" and "FALSE" instead.  

The data is clean in respects to ensuring that every variable have their own column, every observation has its own row and every box / input is just some combination of the variable and observation. The data is however not clean in respects to redundant columns. There are 11 columns used for route 1 to 11 where as 'Route number' should be a distinct column for each observation. There should also be an additional column called 'Route name'. (Specify the route number then which the name of that route is in two columns). 

After cleaning the data according to the instructions, there are also rows of identical data inputs. We could consider evaluating the duplicates in a new column to indicate how many times it was repeated. 


**Answer the following questions using these data:**

*   How many distinct stations are there? Note that stations are identified both by name and by line (e.g. 125th St 8th Avenue; 125st Broadway; 125st Lenox); the distinct function may be useful here.

```{r}
distinct(NYC_Transit_df, line, station_name)
```
465 distinct stations

*   How many stations are ADA compliant?

```{r}
sum(NYC_Transit_df %>% 
                 pull(ada))
```
468 stations (including duplicates)

```{r}
Distinct_ada_df = 
filter(NYC_Transit_df, ada == TRUE) %>% 
  distinct(line, station_name)
```
84 distinct ADA compliant stations

*   What proportion of station entrances / exits without vending allow entrance?

```{r}
NYC_Transit_df %>%
  filter(vending == "NO") %>%
  summarise(proportion= sum(entry = TRUE) / n())
```
0.00546 (5.46%) stations without vending allow entrance

**Reformat data so that route number and route name are distinct variables.**

How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?


## Problem 2

**Read and clean the Mr. Trash Wheel sheet:**

*   specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel

*   use reasonable variable names

*   omit rows that do not include dumpster-specific data

*   round the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)

```{r}
Mr_Trash_Wheel_df = 
  read_xlsx("202309 Trash Wheel Collection Data.xlsx", sheet = 1, 
           na = c("NA", ",", ".")) %>% 
  janitor::clean_names() %>% 
  select(-(x15)) %>% 
  select(-(x16)) %>% 
  mutate(
    sports_balls = 
      round(
        sports_balls),
    sports_balls = as.integer(sports_balls)) %>% 
  mutate(
    wheel_name = "Mr"
  )
```

**Use a similar process to import, clean, and organize the data for Professor Trash Wheel and Gwynnda, and combine this with the Mr. Trash Wheel dataset to produce a single tidy dataset. To keep track of which Trash Wheel is which, you may need to add an additional variable to both datasets before combining.**

```{r}
Professor_Trash_Wheel_df = 
  read_xlsx("202309 Trash Wheel Collection Data.xlsx", sheet = 2, 
           na = c("NA", ",", ".")) %>% 
  janitor::clean_names() %>% 
  mutate(
    wheel_name = "Professor") %>% 
  mutate(
    year = 
      as.character(year)
  )

Gwynnda_Trash_Wheel_df = 
  read_xlsx("202309 Trash Wheel Collection Data.xlsx", sheet = 4, 
           na = c("NA", ",", ".")) %>% 
  janitor::clean_names() %>% 
  mutate(
    wheel_name = "Gwynnda") %>% 
  mutate(
    year = 
      as.character(year)
  )
```

```{r}
Trash_Tidy_df = 
  bind_rows(Mr_Trash_Wheel_df, Professor_Trash_Wheel_df, Gwynnda_Trash_Wheel_df) %>% 
  janitor::clean_names()

arrange(Trash_Tidy_df, dumpster, wheel_name)
```

**Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in the resulting dataset, and give examples of key variables. For available data, what was the total weight of trash collected by Professor Trash Wheel? What was the total number of cigarette butts collected by Gwynnda in June of 2022?**

There are 849 observations and 15 variables in the resulting Trash_Tidy dataframe which combined Mr Trash Wheel, Professor Trash Wheel and Gwynnda Trash Wheel's data. Examples of  key variables include weight_tons (weight of trash collected in tonnes),  wheel_name (distinguishes the source trash wheel of the data observation), and date (the year, month, day which the observation was collected). 

```{r}
sum(Trash_Tidy_df %>% 
      filter(wheel_name == "Professor") %>% 
      pull(weight_tons), 
    na.rm = FALSE
    )
```
The total weight of trash collected by Professor Trash Wheel was 432.52 tonnes. 

```{r}
sum(Trash_Tidy_df %>% 
      filter(wheel_name == "Gwynnda", 
             month == "June",
             year == "2022") %>% 
      pull(cigarette_butts),
    na.rm = FALSE
    )
```
A total of 18120 cigarette butts were collected by Gwynnda in June of 2022.

##Problem 3

**In the first part of this problem, your goal is to create a single, well-organized dataset with all the information contained in these data files. To that end: import, clean, tidy, and otherwise wrangle each of these datasets; check for completeness and correctness across datasets (e.g. by viewing individual datasets and using anti_join); merge to create a single, final dataset; and organize this so that variables and observations are in meaningful orders. Export the result as a CSV in the directory containing the original datasets.**

```{r}
Bakers_df = 
  read_csv(file = "gbb_datasets/bakers.csv", 
           na = c("NA", ",", ".")) %>% 
  janitor::clean_names()

Bakes_df = 
  read_csv(file = "gbb_datasets/bakes.csv", 
           na = c("NA", ",", ".")) %>% 
  janitor::clean_names() %>% 
  mutate(baker = case_when(
    baker == '"Jo"' ~ 'Jo',
    TRUE ~ baker
  ))

Results_df = 
  read_csv(file = "gbb_datasets/results.csv",
           na = c("NA", ",", ".")) %>% 
  janitor::clean_names() %>% 
  { 
    colnames(.) <- as.character(.[2, ])
    .[-2, ]
  } %>% 
  mutate(
    series = as.numeric(series), 
      episode = as.numeric(episode)
    )
```

```{r}
Bakers_df =
  Bakers_df %>%
  mutate(baker = word(baker_name, 1))

Bakers_Bakes_Join_df =
  left_join(Bakers_df, Bakes_df, by = c("baker" = "baker", "series" = "series"))

Bakers_Bakes_Results_Join_df = 
  left_join(Bakers_Bakes_Join_df, Results_df, by = c("baker", "series", "episode")) %>% 
  select(-(baker))
```

```{r}
missing_bakers = Bakes_df %>%
  anti_join(Bakers_df, by = c("baker" = "baker", "series" = "series"))

```


**Describe your data cleaning process, including any questions you have or choices you made. Briefly discuss the final dataset.**


First I established that the dataframes all shared a 'baker_name' or 'baker' variable and I decided that the resulting dataframe should be organised by 'baker'/'baker_name' 

In loading results_df, I realised that the column names were incorrect and that row 2 should be considered as the column names. I re-labled results_df columns with row 2 and deleted row 2. I then also converted results_df variables 'series' and 'episode' from character variables into numeric variables. This was it would be consistent with the bakers and bakes dataframes. 

If I wanted to join the dataframes via the bakers' names, I realised that in Bakers_df the names of the bakers are listed under both their first and last names. This would make it hard to match with the other dataframes as they only had their bakers listed under their first names. I created a new column in the Bakers_df called 'baker' (consistent with the variable name of the other two dataframes) and had it equal to the first word of their name. 

My order of joining was chosen so that in the resulting data frame the variables and observations were in meaningful orders. Starting out with the baker (including the season they appeared on and their personal information), then what they baked and on what episode,  and then lastly the result of that bake on that episode. 

My first join was between the Bakers_df and Bakes_df. I realised that in  Bakes_df, bakers and their baked goods were listed by season but also by episode (in Bakers_df bakers were only listed by the season they appeared in). This meant that the number of rows for Bakers_df 'bakers' needed to be increased to account for each episode that they appeared in in the season. The `"baker" = "baker"` and `"series" = "series"` with the `=` allowed a multiple mapping criteria and pair as many "baker" from Bakers_df to "baker" from Bakes_df. This meant that if a baker in Bakers_df corresponds to multiple entries in Bakes_df, that baker will appear in multiple rows, each with the respective bake.

I put in the "series" to "series" mapping as well because I realised that sometimes two bakers from two different series will have the same name (especially since now I am only working with first names), so to ensure that I had correct mapping I set a second condition of series to make sure that the correct bake went to the correct baker of that season. 

The next join was between the joined Bakers and Bakes dataframe and Results_df. Here since all the necessary rows were available (all the times the baker appeared on the show), this joining only required me to match the baker, series, and episode. I did not need to do multiple mapping and therefore no `=` was needed. (cleaning up the resulting dataframe also involved deleting the baker column that I recreated for the Bakers_df of only the first name and retaining the first and last name 'baker_name' column). 

After all this, I used `anti_join` to see whether I had missed any observations. Checking for bakers in 'Bakers_df' not in 'Bakes_df' I realised that Jo recorded in Bakers_df as Jo was recorded as "Jo" in the Bakes_df. This meant that Jo's information in Bakers_df was not paired with their information in Bakes_df. I went back and `case_when` in the bakers column "Jo" appear it would be renamed as just Jo. 
