p8105_hw2_fp2513
================

## Problem 1

**Read and clean the data; retain line, station, name, station latitude
/ longitude, routes served, entry, vending, entrance type, and ADA
compliance. Convert the entry variable from character (YES vs NO) to a
logical variable (the ifelse or case_match function may be useful).**

``` r
NYC_Transit_df = 
  read_csv(file = "NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
           na = c("NA", ",", ".")) %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(
    entry = 
      case_match(
        entry, 
        "NO" ~ FALSE, 
        "YES" ~ TRUE),
    entry = as.logical(entry))
```

    ## Warning: One or more parsing issues, call `problems()` on your data frame for details,
    ## e.g.:
    ##   dat <- vroom(...)
    ##   problems(dat)

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

**Write a short paragraph about this dataset – explain briefly what
variables the dataset contains, describe your data cleaning steps so
far, and give the dimension (rows x columns) of the resulting dataset.
Are these data tidy?**

After importing and intial cleaning of the data, the NYC_Transit_df
contains 1868 observations (each having its own row; 1868 rows) and 19
variables (19 columns). The data cleaning steps so far include:

1.  First defining the cells with NA, . and empty cells are used to
    indicate a missing value.

2.  Then using `janitor::clean_names()` to clean up the variable column
    names to a consistent lower snake case.

3.  Next, `select()` specified the columns that I wanted to keep,
    including the range from line to entry, and additional vending and
    ada columns

4.  Lastly, `mutate()` converted the inputs in the entry column from
    characters to logical variables. Specifically, using `case_match` to
    chnage every “YES” and “NO” input respectively became “TRUE” and
    “FALSE” instead.

The data is clean in respects to ensuring that every variable have their
own column, every observation has its own row and every box / input is
just some combination of the variable and observation. The data is
however not clean in respects to redundant columns. There are 11 columns
used for route 1 to 11 where as ‘Route number’ should be a distinct
column for each observation. There should also be an additional column
called ‘Route name’. (Specify the route number then which the name of
that route is in two columns).

After cleaning the data according to the instructions, there are also
rows of identical data inputs. We could consider evaluating the
duplicates in a new column to indicate how many times it was repeated.

**Answer the following questions using these data:**

- How many distinct stations are there? Note that stations are
  identified both by name and by line (e.g. 125th St 8th Avenue; 125st
  Broadway; 125st Lenox); the distinct function may be useful here.

``` r
distinct(NYC_Transit_df, line, station_name)
```

    ## # A tibble: 465 × 2
    ##    line     station_name            
    ##    <chr>    <chr>                   
    ##  1 4 Avenue 25th St                 
    ##  2 4 Avenue 36th St                 
    ##  3 4 Avenue 45th St                 
    ##  4 4 Avenue 53rd St                 
    ##  5 4 Avenue 59th St                 
    ##  6 4 Avenue 77th St                 
    ##  7 4 Avenue 86th St                 
    ##  8 4 Avenue 95th St                 
    ##  9 4 Avenue 9th St                  
    ## 10 4 Avenue Atlantic Av-Barclays Ctr
    ## # ℹ 455 more rows

465 distinct stations

- How many stations are ADA compliant?

``` r
sum(NYC_Transit_df %>% 
                 pull(ada))
```

    ## [1] 468

468 stations (including duplicates)

``` r
Distinct_ada_df = 
filter(NYC_Transit_df, ada == TRUE) %>% 
  distinct(line, station_name)
```

84 distinct ADA compliant stations

- What proportion of station entrances / exits without vending allow
  entrance?

``` r
NYC_Transit_df %>%
  filter(vending == "NO") %>%
  summarise(proportion= sum(entry = TRUE) / n())
```

    ## # A tibble: 1 × 1
    ##   proportion
    ##        <dbl>
    ## 1    0.00546

0.00546 (5.46%) stations without vending allow entrance

**Reformat data so that route number and route name are distinct
variables.**

How many distinct stations serve the A train? Of the stations that serve
the A train, how many are ADA compliant?

## Problem 2

**Read and clean the Mr. Trash Wheel sheet:**

- specify the sheet in the Excel file and to omit non-data entries (rows
  with notes / figures; columns containing notes) using arguments in
  read_excel

- use reasonable variable names

- omit rows that do not include dumpster-specific data

- round the number of sports balls to the nearest integer and converts
  the result to an integer variable (using as.integer)

``` r
Mr_Trash_Wheel_df = 
  read_xlsx("202309 Trash Wheel Collection Data.xlsx", sheet = 1, 
           na = c("NA", ",", ".")) %>% 
  janitor::clean_names() %>% 
  select(-(x15)) %>% 
  select(-(x16)) %>% 
  mutate(
    sports_balls = 
      round(
        sports_balls),
    sports_balls = as.integer(sports_balls)) %>% 
  mutate(
    wheel_name = "Mr"
  )
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

**Use a similar process to import, clean, and organize the data for
Professor Trash Wheel and Gwynnda, and combine this with the Mr. Trash
Wheel dataset to produce a single tidy dataset. To keep track of which
Trash Wheel is which, you may need to add an additional variable to both
datasets before combining.**

``` r
Professor_Trash_Wheel_df = 
  read_xlsx("202309 Trash Wheel Collection Data.xlsx", sheet = 2, 
           na = c("NA", ",", ".")) %>% 
  janitor::clean_names() %>% 
  mutate(
    wheel_name = "Professor") %>% 
  mutate(
    year = 
      as.character(year)
  )

Gwynnda_Trash_Wheel_df = 
  read_xlsx("202309 Trash Wheel Collection Data.xlsx", sheet = 4, 
           na = c("NA", ",", ".")) %>% 
  janitor::clean_names() %>% 
  mutate(
    wheel_name = "Gwynnda") %>% 
  mutate(
    year = 
      as.character(year)
  )
```

``` r
Trash_Tidy_df = 
  bind_rows(Mr_Trash_Wheel_df, Professor_Trash_Wheel_df, Gwynnda_Trash_Wheel_df) %>% 
  janitor::clean_names()

arrange(Trash_Tidy_df, dumpster, wheel_name)
```

    ## # A tibble: 849 × 15
    ##    dumpster month    year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 July     2021  2021-07-03 00:00:00        0.93                 15
    ##  2        1 May      2014  2014-05-16 00:00:00        4.31                 18
    ##  3        1 January  2017  2017-01-02 00:00:00        1.79                 15
    ##  4        2 July     2021  2021-07-07 00:00:00        2.26                 15
    ##  5        2 May      2014  2014-05-16 00:00:00        2.74                 13
    ##  6        2 January  2017  2017-01-30 00:00:00        1.58                 15
    ##  7        3 July     2021  2021-07-07 00:00:00        1.62                 15
    ##  8        3 May      2014  2014-05-16 00:00:00        3.45                 15
    ##  9        3 February 2017  2017-02-26 00:00:00        2.32                 18
    ## 10        4 July     2021  2021-07-16 00:00:00        1.76                 15
    ## # ℹ 839 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>, wheel_name <chr>

**Write a paragraph about these data; you are encouraged to use inline
R. Be sure to note the number of observations in the resulting dataset,
and give examples of key variables. For available data, what was the
total weight of trash collected by Professor Trash Wheel? What was the
total number of cigarette butts collected by Gwynnda in June of 2022?**

There are 849 observations and 15 variables in the resulting Trash_Tidy
dataframe which combined Mr Trash Wheel, Professor Trash Wheel and
Gwynnda Trash Wheel’s data. Examples of key variables include
weight_tons (weight of trash collected in tonnes), wheel_name
(distinguishes the source trash wheel of the data observation), and date
(the year, month, day which the observation was collected).

``` r
sum(Trash_Tidy_df %>% 
      filter(wheel_name == "Professor") %>% 
      pull(weight_tons), 
    na.rm = FALSE
    )
```

    ## [1] 432.52

The total weight of trash collected by Professor Trash Wheel was 432.52
tonnes.

``` r
sum(Trash_Tidy_df %>% 
      filter(wheel_name == "Gwynnda", 
             month == "June",
             year == "2022") %>% 
      pull(cigarette_butts),
    na.rm = FALSE
    )
```

    ## [1] 18120

A total of 18120 cigarette butts were collected by Gwynnda in June of
2022.

\##Problem 3

**In the first part of this problem, your goal is to create a single,
well-organized dataset with all the information contained in these data
files. To that end: import, clean, tidy, and otherwise wrangle each of
these datasets; check for completeness and correctness across datasets
(e.g. by viewing individual datasets and using anti_join); merge to
create a single, final dataset; and organize this so that variables and
observations are in meaningful orders. Export the result as a CSV in the
directory containing the original datasets.**

``` r
Bakers_df = 
  read_csv(file = "gbb_datasets/bakers.csv", 
           na = c("NA", ",", ".")) %>% 
  janitor::clean_names()
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
Bakes_df = 
  read_csv(file = "gbb_datasets/bakes.csv", 
           na = c("NA", ",", ".")) %>% 
  janitor::clean_names() %>% 
  mutate(baker = case_when(
    baker == '"Jo"' ~ 'Jo',
    TRUE ~ baker
  ))
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
Results_df = 
  read_csv(file = "gbb_datasets/results.csv",
           na = c("NA", ",", ".")) %>% 
  janitor::clean_names() %>% 
  { 
    colnames(.) <- as.character(.[2, ])
    .[-2, ]
  } %>% 
  mutate(
    series = as.numeric(series), 
      episode = as.numeric(episode)
    )
```

    ## New names:
    ## Rows: 1138 Columns: 5
    ## ── Column specification
    ## ──────────────────────────────────────────────────────── Delimiter: "," chr
    ## (5): ...1, ...2, ...3, ...4, IN = stayed in; OUT = Eliminated; STAR BAKE...
    ## ℹ Use `spec()` to retrieve the full column specification for this data. ℹ
    ## Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## • `` -> `...1`
    ## • `` -> `...2`
    ## • `` -> `...3`
    ## • `` -> `...4`

``` r
Bakers_df =
  Bakers_df %>%
  mutate(baker = word(baker_name, 1))

Bakers_Bakes_Join_df =
  left_join(Bakers_df, Bakes_df, by = c("baker", "series"))

Bakers_Bakes_Results_Join_df = 
  left_join(Results_df, Bakers_Bakes_Join_df, by = c("baker", "series", "episode"))
```

``` r
missing_bakers = Results_df %>%
  anti_join(Bakers_Bakes_Results_Join_df, by = c("baker" = "baker_name", "series" = "series"))
```

``` r
Bakers_Bakes_Results_Join_df = 
Bakers_Bakes_Results_Join_df %>% 
  arrange(series, episode, baker) %>% 
  select(-one_of(c("technical", "result")), everything(), one_of(c("technical", "result")
  ))
```

``` r
write_csv(Bakers_Bakes_Results_Join_df, "gbb_datasets/Bakers_Bakes_Results_Join_df.csv")
```

**Describe your data cleaning process, including any questions you have
or choices you made. Briefly discuss the final dataset.**

First I established that the dataframes all shared a ‘baker_name’ or
‘baker’ variable and I decided that the resulting dataframe should be
organised by ‘baker’/‘baker_name’

In loading results_df, I realised that the column names were incorrect
and that row 2 should be considered as the column names. I re-labled
results_df columns with row 2 and deleted row 2. I then also converted
results_df variables ‘series’ and ‘episode’ from character variables
into numeric variables. This was it would be consistent with the bakers
and bakes dataframes.

If I wanted to join the dataframes via the bakers’ names, I realised
that in Bakers_df the names of the bakers are listed under both their
first and last names. This would make it hard to match with the other
dataframes as they only had their bakers listed under their first names.
I created a new column in the Bakers_df called ‘baker’ (consistent with
the variable name of the other two dataframes) and had it equal to the
first word of their name.

My first join was between the Bakers_df and Bakes_df. I realised that in
Bakes_df, bakers and their baked goods were listed by season but also by
episode (in Bakers_df bakers were only listed by the season they
appeared in). This meant that the number of rows for Bakers_df ‘bakers’
needed to be increased to account for each episode that they appeared in
in the season. I put in the “series” to “series” mapping as well because
I realised that sometimes two bakers from two different series will have
the same name (especially since now I am only working with first names),
so to ensure that I had correct mapping I set a second condition of
series to make sure that the correct bake went to the correct baker of
that season.

I decided to left join between Results_df and Bakers_Bakes_df, because
the Results_df included results regarding the season 9 and 10 of the
show, of which the Bakers_Bakes_df did not have. Cleaning up the
resultant Results_Bakers_Bakes_df I considered deleting the bakers
column and only keeping the bakers_name column but then I realised that
the Results_df only included information about the bakers’ first names.

After all this, I used `anti_join` to see whether I had missed any
observations. Checking for bakers in ‘Bakers_df’ not in ‘Bakes_df’ I
realised that Jo recorded in Bakers_df as Jo was recorded as “Jo” in the
Bakes_df. This meant that Jo’s information in Bakers_df was not paired
with their information in Bakes_df. I went back and `case_when` in the
bakers column “Jo” appear it would be renamed as just Jo.

Lastly, I arranged the final Bakers_Bakes_Results_df rows, so that it is
ordered by series, episode and baker’s name. I also re-ordered the
columns to be easier to read. Starting out with the baker (including the
season they appeared on and their personal information), then what they
baked and on what episode, and then lastly the result of that bake on
that episode.

The final data set has 1137 observations with 11 variables.

**Create a reader-friendly table showing the star baker or winner of
each episode in Seasons 5 through 10. Comment on this table – were there
any predictable overall winners? Any surprises?**

``` r
S5_10_Star_Win = 
  filter(Bakers_Bakes_Results_Join_df, series %in% 5:10 & 
          result %in% c("STAR BAKER", "WINNER"))
```

Surprisingly, in season 5 Nancy Birtwhistle won but she only had 1 STAR
BAKER award which was in fact in the first episode. Where as in the same
season Richard Burr was the STAR BAKER for half of the season’s episodes
and even for the 3 episodes right before the last yet he did not win.

Season 6 was not too surprising, Nadiya Hussain won the season but they
were the STAR BAKER for the two episodes prior to the finale.

Season 7 Candice Brown winner was not unsurprising with several STAR
BAKER awards throughout the season. This is similar to the season 8
winner Sophie Faldo and season 9 winner Rahul.

Season 10 was a surprising win, as David won in the last episode without
ever being the STAR BAKER in any episode prior.

**Import, clean, tidy, and organize the viewership data in viewers.csv.
Show the first 10 rows of this dataset. What was the average viewership
in Season 1? In Season 5?**

``` r
Viewers_df = 
  read_csv(file = "gbb_datasets/viewers.csv", 
           na = c("NA", ",", ".")) %>% 
  janitor::clean_names()
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
